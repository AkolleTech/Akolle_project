# -*- coding: utf-8 -*-
"""tummer detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kUo8bRO_YT0YCpC7m5jYNREnd1ea2tqu
"""

!nvidia-smi

import tensorflow as tf
import numpy as np
import cv2
import os
import matplotlib.pyplot as plt
import imutils
import uuid
import glob
from tensorflow.keras.applications import VGG16

path = r"/content/drive/MyDrive/concrete_data_week4/test"
category = os.listdir(path)
print(category)

images = []
label = []

for i in category:
    class_num = category.index(i)
    paths = os.path.join(path,i)
    print("hello")
    for img in os.listdir(paths):
        try:
            c = 0
            image_size = 224
            image = cv2.imread(os.path.join(paths,img))
            image_resize = cv2.resize(image,(image_size,image_size))

            DIR = r"/content/drive/MyDrive/concrete_data_week4/test/New"
            target = os.path.join(DIR, i)

            if not os.path.exists(target):
                os.mkdir(target)
                print("folder is created")
            os.chdir(target)
            image_name = os.path.join(DIR,i,i+'.'+'{}.jpg'.format(str(uuid.uuid1())))
            cv2.imwrite(image_name,image_resize)
            images.append(image_resize)
            label.append(class_num)
            c += 1
        except Exeption as e:
            print("it will pass")

plt.imshow(images[250])
print(len(images))

normalized_image = np.array(images)/255
labels = np.array(label)

normalized_image[0].shape

print(labels[499])

#if the classification is more than 2 we can use label encoder let's do this below
label_encoder = []
for lab in label:
    if lab == 0:
        lab = "Cracked"

    else:
        lab = "Normal"

    label_encoder.append(lab)
print(label_encoder[250])

from sklearn import preprocessing

pre = preprocessing.LabelEncoder()
pre.fit(label_encoder)
labeled_set = pre.transform(label_encoder)
print(labeled_set[250])

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(normalized_image,labeled_set)

y_tests = pre.inverse_transform(y_test)
print(y_tests)
print(len(y_tests))

size = 224
model = VGG16(weights="imagenet",include_top = False,input_shape=(size,size,3))

for layer in model.layers:
    layer.trainable = False

model.summary()

feature_extraction = model.predict(x_train)

features = feature_extraction.reshape(feature_extraction.shape[0],-1)
x_trains = features

import xgboost as xgb

models = xgb.XGBClassifier()
models.fit(x_trains,y_train)

x_test_features = model.predict(x_test)
x_tests = x_test_features.reshape(x_test_features.shape[0],-1)

prediction = models.predict(x_tests)

len(prediction)
prediction = pre.inverse_transform(prediction)

prediction

from sklearn import metrics

print("Accuracy = ", metrics.accuracy_score(y_tests,prediction))

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_tests,prediction)
print(cm)

import seaborn as sns

sns.heatmap(cm, annot = True)

